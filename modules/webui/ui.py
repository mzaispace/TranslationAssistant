import chainlit as cl
import asyncio
from chainlit.input_widget import Select, Switch

# ============ é…ç½®åŒºåŸŸ ============
CONFIG = {
    "model_name": "Qwen2.5-7B-Instruct",
    "gpu_index": 0,
    "max_history": 10,
    "use_mock_model": False,  # ã€è°ƒè¯•ç”¨ã€‘å¦‚æœä¸º Trueï¼Œå°†ä¸åŠ è½½çœŸå®æ¨¡å‹ï¼Œä»…æµ‹è¯•UI
}

# æ–¹ä¾¿ UI æ˜¾ç¤ºåç§°å’Œå†…éƒ¨ ID äº’è½¬
ROLE_NAME_TO_KEY = {
    "äº§å“ç»ç†": "product",
    "ç ”å‘å·¥ç¨‹å¸ˆ": "dev"
}


# è§’è‰²è¯¦ç»†é…ç½®
ROLE_MAP = {
    "product": {
        "name": "äº§å“ç»ç†",
        "icon": "ğŸ“Š",
        "description": "å…³æ³¨ç”¨æˆ·éœ€æ±‚ã€å¸‚åœºåˆ†æã€åŠŸèƒ½è§„åˆ’",
        "prompt": """ä½ æ˜¯ä¸€ä½èµ„æ·±äº§å“ç»ç† (PM)ã€‚ä½ çš„æ ¸å¿ƒæ€ç»´æ¨¡å¼æ˜¯ï¼š
1. ç”¨æˆ·è§†è§’ï¼šç—›ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿåœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ
2. å•†ä¸šä»·å€¼ï¼šROIå¦‚ä½•ï¼Ÿå¸‚åœºç©ºé—´å¤šå¤§ï¼Ÿ
3. ä¼˜å…ˆçº§ï¼šMVPæ˜¯ä»€ä¹ˆï¼Ÿè¿­ä»£è®¡åˆ’å¦‚ä½•ï¼Ÿ
è¯·ç”¨ä¸“ä¸šçš„PMæœ¯è¯­ï¼ˆå¦‚PRDã€ç”¨æˆ·ç”»åƒã€è½¬åŒ–ç‡ç­‰ï¼‰å›ç­”ï¼Œç»“æ„æ¸…æ™°ã€‚"""
    },
    "dev": {
        "name": "ç ”å‘å·¥ç¨‹å¸ˆ",
        "icon": "ğŸ’»",
        "description": "å…³æ³¨æŠ€æœ¯å®ç°ã€æ¶æ„è®¾è®¡ã€ä»£ç è´¨é‡",
        "prompt": """ä½ æ˜¯ä¸€ä½èµ„æ·±ç ”å‘å·¥ç¨‹å¸ˆ (Dev)ã€‚ä½ çš„æ ¸å¿ƒæ€ç»´æ¨¡å¼æ˜¯ï¼š
1. å¯è¡Œæ€§ï¼šæŠ€æœ¯æ–¹æ¡ˆæ˜¯å¦æˆç†Ÿï¼Ÿ
2. ç¨³å®šæ€§ï¼šé«˜å¹¶å‘æ€ä¹ˆå¤„ç†ï¼Ÿå¼‚å¸¸æ€ä¹ˆå…œåº•ï¼Ÿ
3. æ‰©å±•æ€§ï¼šæ¶æ„æ˜¯å¦è§£è€¦ï¼Ÿä»£ç æ˜¯å¦æ•´æ´ï¼Ÿ
è¯·ç”¨ä¸“ä¸šçš„æŠ€æœ¯æœ¯è¯­ï¼ˆå¦‚å¾®æœåŠ¡ã€è®¾è®¡æ¨¡å¼ã€æ—¶é—´å¤æ‚åº¦ç­‰ï¼‰å›ç­”ï¼Œæä¾›ä»£ç ç‰‡æ®µã€‚"""
    }
}

# ============ æ¨¡æ‹Ÿæ¨¡å‹ï¼ˆç”¨äºæ— GPUç¯å¢ƒæµ‹è¯•UIï¼‰ ============
class MockModel:
    def generate_response(self, user_query, history, sys_prompt, stream=True):
        yield f"ã€æ¨¡æ‹Ÿå›å¤ã€‘\næ”¶åˆ°é—®é¢˜ï¼š{user_query}\n\nå½“å‰è§’è‰²è®¾å®šï¼š\n{sys_prompt[:50]}...\n\n(è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å›å¤ï¼Œè¯·åœ¨ä»£ç ä¸­è®¾ç½® use_mock_model=False ä»¥åŠ è½½çœŸå®æ¨¡å‹)"




# ============ åˆå§‹åŒ–é€»è¾‘ ============
chat_model = None

async def init_model():
    global chat_model
    if CONFIG["use_mock_model"]:
        chat_model = MockModel()
        return "âœ… æ¨¡æ‹Ÿæ¨¡å‹å·²åŠ è½½ (UIæµ‹è¯•æ¨¡å¼)"

    try:
        try:
            from modules.agents.inference.local_model_infer import LocalModelChat
            import torch
        except ImportError:
            # å¦‚æœæ²¡æœ‰æœ¬åœ°æ–‡ä»¶ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæˆ–æŠ¥é”™
            print("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹æ¨¡å—ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼ã€‚")
            chat_model = MockModel()
            return "âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å—ï¼Œå·²åˆ‡æ¢è‡³æ¨¡æ‹Ÿæ¨¡å¼"

        chat_model = LocalModelChat(
            base_model_name=CONFIG["model_name"],
            gpu_index=CONFIG["gpu_index"]
        )
        device = 'GPU' if torch.cuda.is_available() else 'CPU'
        return f"âœ… æ¨¡å‹å·²åŠ è½½ ({device}): {CONFIG['model_name']}"
    except Exception as e:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"

# ============ Chainlit äº‹ä»¶å¤„ç† ============

@cl.on_chat_start
async def start_chat():
    """ä¼šè¯åˆå§‹åŒ–"""

    # 1. åˆå§‹åŒ– Session å˜é‡
    cl.user_session.set("history", [])
    cl.user_session.set("role", "product")

    # 2. è®¾ç½® Chat Settings
    # ã€ä¿®æ­£ç‚¹ã€‘values å¿…é¡»æ˜¯åˆ—è¡¨ï¼Œä¸èƒ½æ˜¯å­—å…¸
    settings = await cl.ChatSettings(
        [
            Select(
                id="role_select",
                label="ğŸ­ å½“å‰å¯¹è¯è§’è‰²",
                values=list(ROLE_NAME_TO_KEY.keys()), # è¿™é‡Œæ”¹ä¸º ["äº§å“ç»ç†", "ç ”å‘å·¥ç¨‹å¸ˆ"]
                initial_index=0,
                description="åˆ‡æ¢åï¼ŒAIå°†ç«‹å³ä»¥æ–°èº«ä»½è¿›è¡Œå›ç­”"
            ),
            Switch(
                id="show_thinking",
                label="ğŸ’¡ æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹",
                initial=True
            ),
        ]
    ).send()

    # 3. æ˜¾ç¤ºåŠ è½½ä¸­
    loading_msg = cl.Message(content="ğŸ”„ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...", author="System")
    await loading_msg.send()

    # 4. åŠ è½½æ¨¡å‹
    status_text = await init_model()
    loading_msg.content = status_text
    await loading_msg.update()

    # 5. å‘é€æ¬¢è¿å¡ç‰‡
    await send_welcome_card()


async def send_welcome_card():
    """å‘é€å¸¦æœ‰å¿«æ·æ“ä½œçš„æ¬¢è¿å¡ç‰‡"""
    actions = [
        cl.Action(name="set_role_product", value="product", label="ğŸ“Š åˆ‡æ¢ä¸ºäº§å“ç»ç†", description="ä¾§é‡ä¸šåŠ¡ä¸ç”¨æˆ·"),
        cl.Action(name="set_role_dev", value="dev", label="ğŸ’» åˆ‡æ¢ä¸ºç ”å‘å·¥ç¨‹å¸ˆ", description="ä¾§é‡æŠ€æœ¯ä¸å®ç°"),
        cl.Action(name="clear_history", value="clear", label="ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", description="å¼€å§‹æ–°è¯é¢˜")
    ]

    content = f"""
# ğŸ¤– æ™ºèƒ½ç ”å‘åŠ©æ‰‹
    
æ¬¢è¿ä½¿ç”¨ï¼è¯·é€‰æ‹©ä¸‹æ–¹çš„ **å¿«æ·æŒ‰é’®** æˆ–ä½¿ç”¨ **è¾“å…¥æ¡†å·¦ä¾§çš„è®¾ç½®å›¾æ ‡** æ¥åˆ‡æ¢è§’è‰²ã€‚
    
**å½“å‰é»˜è®¤è§’è‰²ï¼š** {ROLE_MAP['product']['icon']} {ROLE_MAP['product']['name']}
"""
    await cl.Message(content=content, actions=actions).send()


@cl.on_settings_update
async def setup_agent(settings):
    """å½“ç”¨æˆ·åœ¨ä¾§è¾¹æ ä¿®æ”¹è®¾ç½®æ—¶è§¦å‘"""

    # ç›‘å¬è§’è‰²åˆ‡æ¢
    if "role_select" in settings:
        selected_name = settings["role_select"] # è·å–åˆ°çš„æ˜¯ "äº§å“ç»ç†"
        # ã€ä¿®æ­£ç‚¹ã€‘å°†ä¸­æ–‡åç§°è½¬æ¢å›å†…éƒ¨ key ("product")
        new_role_key = ROLE_NAME_TO_KEY.get(selected_name)

        if new_role_key:
            await switch_role(new_role_key)



@cl.action_callback("set_role_product")
async def on_action_product(action):
    await switch_role("product")
    # å¯é€‰ï¼šç§»é™¤æŒ‰é’®ä»¥é˜²æ­¢é‡å¤ç‚¹å‡»ï¼Œæˆ–è€…ä¿ç•™
    # await action.remove()

@cl.action_callback("set_role_dev")
async def on_action_dev(action):
    await switch_role("dev")

@cl.action_callback("clear_history")
async def on_action_clear(action):
    cl.user_session.set("history", [])
    await cl.Message(content="ğŸ—‘ï¸ è®°å¿†å·²æ¸…é™¤ï¼Œè®©æˆ‘ä»¬é‡æ–°å¼€å§‹ã€‚", author="System").send()

async def switch_role(role_key):
    """ç»Ÿä¸€çš„è§’è‰²åˆ‡æ¢é€»è¾‘"""
    current_role = cl.user_session.get("role")
    if current_role == role_key:
        return # è§’è‰²æœªå˜ï¼Œæ— éœ€æ“ä½œ

    target_role = ROLE_MAP.get(role_key)
    if not target_role:
        return

    # æ›´æ–° Session
    cl.user_session.set("role", role_key)

    # å‘é€ç³»ç»Ÿé€šçŸ¥
    msg = cl.Message(
        content=f"**èº«ä»½å·²åˆ‡æ¢** \n\næˆ‘ç°åœ¨æ˜¯ **{target_role['icon']} {target_role['name']}**ã€‚\n_{target_role['description']}_",
        author="System"
    )
    await msg.send()

    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ï¼Œæ›´æ–°å¤´åƒ (Avatar)
    # æ³¨æ„ï¼šChainlit çš„å¤´åƒé€šå¸¸åœ¨ chainlit.md æˆ–é…ç½®ä¸­é™æ€å®šä¹‰ï¼Œ
    # ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¿®æ”¹ msg.author åœ¨å‘é€æ¶ˆæ¯æ—¶åŠ¨æ€åŒºåˆ†ã€‚


@cl.on_message
async def handle_message(message: cl.Message):
    """æ ¸å¿ƒå¯¹è¯é€»è¾‘"""
    global chat_model

    if not chat_model:
        await cl.Message(content="âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚", author="System").send()
        return

    # 1. è·å–å½“å‰çŠ¶æ€
    role_key = cl.user_session.get("role", "product")
    role_config = ROLE_MAP[role_key]
    history = cl.user_session.get("history", [])

    # 2. å‡†å¤‡ UI
    # ä½¿ç”¨åŠ¨æ€ Author Name æ¥å±•ç¤ºå½“å‰è§’è‰²
    author_name = f"{role_config['name']} AI"
    # ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ç‰¹å®šçš„å¤´åƒï¼Œå¦‚æœé…ç½®äº† public/avatars/

    msg = cl.Message(content="", author=author_name)
    await msg.send()

    # 3. å‡†å¤‡ Prompt
    sys_prompt = role_config["prompt"]

    try:
        # 4. ç”Ÿæˆå›å¤
        stream = chat_model.generate_response(
            user_query=message.content,
            history=history,
            sys_prompt=sys_prompt,
            stream=True
        )

        full_response = ""
        for token in stream:
            await msg.stream_token(token)
            full_response += token
            await asyncio.sleep(0.005) # ç¨å¾®å¹³æ»‘ä¸€ç‚¹æµå¼è¾“å‡º

        await msg.update()

        # 5. æ›´æ–°å†å²
        history.append({"role": "user", "content": message.content})
        history.append({"role": "assistant", "content": full_response})

        # æˆªæ–­å†å²ä»¥é˜²çˆ†æ˜¾å­˜
        if len(history) > CONFIG["max_history"]:
            history = history[-CONFIG["max_history"]:]

        cl.user_session.set("history", history)

    except Exception as e:
        await cl.Message(content=f"âŒ ç”Ÿæˆå‡ºé”™: {str(e)}", author="System").send()




if __name__ == "__main__":
    from chainlit.cli import run_chainlit
    run_chainlit(__file__)